def _log_token_usage(response, model_name="æœªçŸ¥æ¨¡å‹"):
    """
    é€šç”¨ token ä½¿ç”¨æ—¥å¿—æ‰“å°å‡½æ•°ï¼Œå…¼å®¹å¤šç§ LLM å“åº”æ ¼å¼
    """
    print(1)
    try:
        usage = None

        # âœ… LangChain ChatOpenAI æ ¼å¼
        if hasattr(response, "response_metadata"):
            usage = response.response_metadata.get("token_usage")

        # âœ… OpenAI Python SDK æ ¼å¼
        elif hasattr(response, "usage_metadata"):
            usage = response.usage_metadata

        # âœ… Qwen / vLLM / é€šä¹‰åƒé—® æ ¼å¼
        elif hasattr(response, "additional_kwargs") and response.additional_kwargs:
            usage = response.additional_kwargs.get("usage", {})

        # âœ… é€šä¹‰åƒé—®å…¼å®¹æ¨¡å¼çš„æ ‡å‡†å­—æ®µ
        elif hasattr(response, "usage"):
            usage = getattr(response, "usage")
        print(usage)
        if usage:
            if isinstance(usage, dict):
                input_tokens = usage.get("input_tokens") or usage.get("prompt_tokens", "N/A")
                output_tokens = usage.get("output_tokens") or usage.get("completion_tokens", "N/A")
                total_tokens = usage.get("total_tokens", "N/A")
            else:
                # CompletionUsage å¯¹è±¡çš„å…¸å‹ç»“æ„
                input_tokens = getattr(usage, "input_tokens", None) or getattr(usage, "prompt_tokens", "N/A")
                output_tokens = getattr(usage, "output_tokens", None) or getattr(usage, "completion_tokens", "N/A")
                total_tokens = getattr(usage, "total_tokens", "N/A")
            print(
                f"ğŸ“Š [{model_name}] Tokenä½¿ç”¨æƒ…å†µ - è¾“å…¥: {input_tokens}, è¾“å‡º: {output_tokens}, æ€»è®¡: {total_tokens}"
            )
        else:
            print(f"âš ï¸ [{model_name}] å½“å‰æ¥å£æœªè¿”å› token ä½¿ç”¨ä¿¡æ¯ã€‚")

    except Exception as e:
        print(f"âŒ è§£æ token ä½¿ç”¨ä¿¡æ¯å¤±è´¥: {e}")